{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construcción de un recomendador con Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "El objetivo general de la actividad será construir un recomendador de películas utilizando el método ALS (Alternating Least Squares), con un dataset que contiene las puntuaciones otorgadas por los usuarios a distintas películas.\n",
    "\n",
    "Dividiremos la actividad en dos apartados, en el primero prepararemos y entrenaremos el modelo, y en el segundo evaluaremos el resultado y realizaremos algunas recomendaciones utilizando el modelo de recomendación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entrenamiento del modelo\n",
    "\n",
    "Comenzamos importando las liberías y configurando Spark para que se ejecute en modo local así como establecemos el nombre de nuestra aplicación, que en este caso será \"movies_recommender\". Tras esto, inicializamos Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql.functions import col, explode\n",
    "\n",
    "spark_conf = SparkConf().setMaster(\"local\").setAppName(\"movies_recommender\")\n",
    "\n",
    "spark = SparkSession.builder.config(conf=spark_conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos cargando los datos de puntuación de los usuarios, el cual se trata de un dataset en csv con cuatro columnas:\n",
    "- El usuario (user_id).\n",
    "- El id de la película (item_id).\n",
    "- La puntuación (rating).\n",
    "- La fecha (timestamp), que en este caso no nos será necesaria.\n",
    "\n",
    "Mostramos unas líneas del dataframe y el esquema, para asegurarnos de que se ha cargado correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+---------+\n",
      "|user_id|item_id|rating|timestamp|\n",
      "+-------+-------+------+---------+\n",
      "|    196|    242|     3|881250949|\n",
      "|    186|    302|     3|891717742|\n",
      "|     22|    377|     1|878887116|\n",
      "|    244|     51|     2|880606923|\n",
      "|    166|    346|     1|886397596|\n",
      "+-------+-------+------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- item_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.options(delimiter=\"\\t\", header=False, inferSchema=True).csv(\"./ml-100k/u.data\").toDF(\"user_id\", \"item_id\", \"rating\", \"timestamp\")\n",
    "\n",
    "data.show(5)\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También cargamos el archivo que contiene información detallada de las películas, que aunque no es necesario para entrenar el recomendador, lo utilizaremos más adelante para poder visualizarlo de una forma más \"human-friendly\", utilizando los títulos de las películas en lugar del id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|item_id|           tittle|\n",
      "+-------+-----------------+\n",
      "|      1| Toy Story (1995)|\n",
      "|      2| GoldenEye (1995)|\n",
      "|      3|Four Rooms (1995)|\n",
      "|      4|Get Shorty (1995)|\n",
      "|      5|   Copycat (1995)|\n",
      "+-------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies = spark.read.options(delimiter=\"|\", header=False, inferSchema=True).csv(\"./ml-100k/u.item\").select(col(\"_c0\").alias(\"item_id\"), col(\"_c1\").alias(\"tittle\"))\n",
    "movies.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es separar el conjunto de datos en dos subconjuntos, uno de entrenamiento y otro de test que utilizaremos respectivamente para entrenar el modelo y para evaluarlo. Utilizamos `.cache()` sobre el dataframe de entrenamiento para mantenerlo en memoria y mejorar el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits= data.randomSplit([0.7, 0.3], 1234)\n",
    "\n",
    "training_df = splits[0]\n",
    "training_df.cache()\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez realizado todo lo anterior, ya podemos preparar el entrenamiento de nuestro recomendador. Para ello debemos indicarle qué columna del dataframe representa a los usuarios (user_id), qué columna representa los elementos a recomendar (item_id) y qué columna representa las puntuaciones (rating). Por otro lado, utilizamos el parámetro `coldStartStrategy=\"drop\"` para evitar que aparezcan valores \"nan\" en caso de que existan usuarios del conjunto de pruebas que no aparezcan en el de entrenamiento durante la validación cruzada.\n",
    "\n",
    "Para el proceso de validación cruzada, preparamos un grid con varios valores para los parámetros `rank` y `regParam`, un evaluador en base a la métrica RMSE, y finalmente, entrenamos el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(userCol=\"user_id\", itemCol=\"item_id\", ratingCol=\"rating\", coldStartStrategy=\"drop\") \n",
    "als_grid = ParamGridBuilder().addGrid(als.rank, [10, 50, 100]).addGrid(als.regParam, [0.01, 0.05, 0.1]).build()\n",
    "als_evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=als_grid, evaluator=als_evaluator, numFolds=5)\n",
    "\n",
    "#entrenamos\n",
    "cv_model = cv.fit(training_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluación y predicciones\n",
    "\n",
    "Teniendo ya entrenado a nuestro recomendador, pasaremos a aplicar el modelo sobre el conjunto de test y evaluar la calidad del resultado mediante el valor de RMSE.\n",
    "\n",
    "Al ejecutar el bloque de código que aparece a continuación podremos comprobar que obtenemos un valor de 0.93, que teniendo en cuenta el rango de las puntuaciones (de 1 a 5), parece un margen de error aceptable de cara a obtener recomendaciones que serán del agrado de los usuarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|rating|prediction|\n",
      "+------+----------+\n",
      "|     3| 1.9691514|\n",
      "|     4| 4.1209908|\n",
      "|     5|  3.698054|\n",
      "|     2|  3.153656|\n",
      "|     4|  3.020012|\n",
      "+------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "RMSE en test: 0.9255832687243486\n"
     ]
    }
   ],
   "source": [
    "prediction_test = cv_model.transform(test_df)\n",
    "\n",
    "prediction_test.select(\"rating\", \"prediction\").show(5)\n",
    "\n",
    "print(\"RMSE en test: {}\".format(als_evaluator.evaluate(prediction_test, {als_evaluator.metricName: \"rmse\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez validado el resultado, podemos utilizar la función `recommendForAllUsers` para generar un nuevo dataframe que contenga recomendaciones para los usuarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------------------------------------------+\n",
      "|user_id|recommendations                                        |\n",
      "+-------+-------------------------------------------------------+\n",
      "|471    |[[102, 4.5626817], [140, 4.5159774], [8, 4.4912596]]   |\n",
      "|463    |[[887, 4.380709], [19, 4.2427382], [221, 4.145413]]    |\n",
      "|833    |[[1597, 4.6237516], [1187, 4.492218], [1019, 4.444743]]|\n",
      "|496    |[[56, 4.549359], [320, 4.4464393], [190, 4.2504497]]   |\n",
      "|148    |[[169, 4.957275], [408, 4.806561], [173, 4.714294]]    |\n",
      "|540    |[[1449, 4.706043], [318, 4.627708], [169, 4.6172495]]  |\n",
      "|392    |[[1463, 4.9152503], [483, 4.8581896], [199, 4.7037654]]|\n",
      "|243    |[[1449, 4.47582], [511, 4.351343], [582, 4.343897]]    |\n",
      "|623    |[[496, 4.719715], [318, 4.5986795], [50, 4.5773196]]   |\n",
      "|737    |[[127, 4.6581316], [60, 4.651312], [175, 4.6235495]]   |\n",
      "|897    |[[64, 4.870203], [318, 4.7335334], [496, 4.637326]]    |\n",
      "|858    |[[127, 4.267202], [689, 4.177561], [272, 4.0020847]]   |\n",
      "|31     |[[514, 4.7119093], [175, 4.67399], [1019, 4.6632404]]  |\n",
      "|516    |[[909, 4.904736], [408, 4.803866], [1062, 4.8023553]]  |\n",
      "|580    |[[50, 4.643648], [181, 4.5968304], [172, 4.461535]]    |\n",
      "|251    |[[64, 4.6563306], [483, 4.646705], [318, 4.5737457]]   |\n",
      "|451    |[[313, 4.452294], [333, 4.216593], [331, 4.138097]]    |\n",
      "|85     |[[1463, 4.3946667], [483, 4.2739964], [134, 4.247064]] |\n",
      "|137    |[[50, 5.187965], [195, 5.1874623], [172, 5.063369]]    |\n",
      "|808    |[[272, 5.3288503], [315, 5.0655947], [483, 5.007069]]  |\n",
      "+-------+-------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommendations = cv_model.bestModel.recommendForAllUsers(3)\n",
    "\n",
    "recommendations.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que las recomendaciones aparecen en una columna de tipo array, podemos utilizar `explode` para separar ese array en filas y poder hacer un `join` con el dataframe que cargamos al principio con los títulos de las películas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+---------------------------------------------+\n",
      "|item_id|user_id|rating   |tittle                                       |\n",
      "+-------+-------+---------+---------------------------------------------+\n",
      "|102    |471    |4.5626817|Aristocats, The (1970)                       |\n",
      "|140    |471    |4.5159774|Homeward Bound: The Incredible Journey (1993)|\n",
      "|8      |471    |4.4912596|Babe (1995)                                  |\n",
      "|887    |463    |4.380709 |Eve's Bayou (1997)                           |\n",
      "|19     |463    |4.2427382|Antonia's Line (1995)                        |\n",
      "+-------+-------+---------+---------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "single_recommendations = recommendations \\\n",
    "    .withColumn(\"rec\", explode(\"recommendations\")) \\\n",
    "    .select(\"user_id\", col(\"rec.item_id\"), col(\"rec.rating\"))\n",
    "\n",
    "single_recommendations.join(movies, on=\"item_id\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, podemos filtrar el dataframe de entrenamiento utilizando uno de los user_id que vemos en las recomendaciones y utilizar de nuevo un join, para poder comparar las películas recomendadas para ese usuario con las que ha visto anteriormente. En este caso (user_id = 471) vemos que sus peliculas más puntuadas son películas infantiles como Aladdin o Home Alone, que en general cuadran con el tipo de película que aparece en las recomendaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+---------+---------------------------------------------+\n",
      "|item_id|user_id|rating|timestamp|tittle                                       |\n",
      "+-------+-------+------+---------+---------------------------------------------+\n",
      "|627    |471    |1     |889827881|Robin Hood: Prince of Thieves (1991)         |\n",
      "|588    |471    |1     |889827881|Beauty and the Beast (1991)                  |\n",
      "|420    |471    |1     |889828027|Alice in Wonderland (1951)                   |\n",
      "|596    |471    |1     |889827881|Hunchback of Notre Dame, The (1996)          |\n",
      "|432    |471    |1     |889827822|Fantasia (1940)                              |\n",
      "|71     |471    |3     |889828154|Lion King, The (1994)                        |\n",
      "|50     |471    |3     |889827757|Star Wars (1977)                             |\n",
      "|95     |471    |4     |889827822|Aladdin (1992)                               |\n",
      "|1      |471    |4     |889827881|Toy Story (1995)                             |\n",
      "|172    |471    |4     |889827822|Empire Strikes Back, The (1980)              |\n",
      "|8      |471    |5     |889827881|Babe (1995)                                  |\n",
      "|225    |471    |5     |889828026|101 Dalmatians (1996)                        |\n",
      "|82     |471    |5     |889827822|Jurassic Park (1993)                         |\n",
      "|393    |471    |5     |889827918|Mrs. Doubtfire (1993)                        |\n",
      "|94     |471    |5     |889828081|Home Alone (1990)                            |\n",
      "|102    |471    |5     |889828081|Aristocats, The (1970)                       |\n",
      "|422    |471    |5     |889827982|Aladdin and the King of Thieves (1996)       |\n",
      "|140    |471    |5     |889827918|Homeward Bound: The Incredible Journey (1993)|\n",
      "+-------+-------+------+---------+---------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_df.join(movies, on=\"item_id\").filter(data.user_id == 471).orderBy(\"rating\").show(n=100,truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
